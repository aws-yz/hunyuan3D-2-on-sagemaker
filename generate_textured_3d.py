#!/usr/bin/env python3
import boto3
import json
import base64
from PIL import Image, ImageDraw
from io import BytesIO

def create_colorful_robot():
    """åˆ›å»ºä¸€ä¸ªå½©è‰²çš„æœºå™¨äººå›¾ç‰‡"""
    img = Image.new('RGB', (512, 512), color=(240, 240, 240))  # æµ…ç°èƒŒæ™¯
    draw = ImageDraw.Draw(img)
    
    # ç»˜åˆ¶å½©è‰²æœºå™¨äºº
    # å¤´éƒ¨ - è“è‰²
    draw.rectangle([200, 100, 300, 200], fill=(70, 130, 180), outline=(0, 0, 0), width=3)
    # çœ¼ç› - çº¢è‰²
    draw.ellipse([220, 130, 240, 150], fill=(255, 50, 50))
    draw.ellipse([260, 130, 280, 150], fill=(255, 50, 50))
    # èº«ä½“ - ç»¿è‰²
    draw.rectangle([180, 200, 320, 350], fill=(60, 179, 113), outline=(0, 0, 0), width=3)
    # æ‰‹è‡‚ - æ©™è‰²
    draw.rectangle([120, 220, 180, 280], fill=(255, 140, 0), outline=(0, 0, 0), width=2)
    draw.rectangle([320, 220, 380, 280], fill=(255, 140, 0), outline=(0, 0, 0), width=2)
    # è…¿ - ç´«è‰²
    draw.rectangle([200, 350, 240, 450], fill=(147, 112, 219), outline=(0, 0, 0), width=2)
    draw.rectangle([260, 350, 300, 450], fill=(147, 112, 219), outline=(0, 0, 0), width=2)
    
    return img

def generate_textured_model():
    runtime = boto3.client('sagemaker-runtime', region_name='us-east-1')
    endpoint_name = 'hunyuan3d-custom-endpoint'
    
    # åˆ›å»ºå½©è‰²æœºå™¨äººå›¾ç‰‡
    print("ğŸŒˆ åˆ›å»ºå½©è‰²æœºå™¨äººå›¾ç‰‡...")
    img = create_colorful_robot()
    
    # ä¿å­˜è¾“å…¥å›¾ç‰‡
    img.save('colorful_robot_input.png')
    print("ğŸ“¸ å½©è‰²è¾“å…¥å›¾ç‰‡å·²ä¿å­˜åˆ°: colorful_robot_input.png")
    
    # è½¬æ¢ä¸ºbase64
    buffer = BytesIO()
    img.save(buffer, format='PNG')
    img_b64 = base64.b64encode(buffer.getvalue()).decode()
    
    # å¯ç”¨çº¹ç†ç”Ÿæˆçš„å‚æ•°
    test_payload = {
        "image": img_b64,
        "texture": True,  # ğŸ¨ å¯ç”¨çº¹ç†ç”Ÿæˆï¼
        "num_inference_steps": 8,
        "seed": 42,
        "guidance_scale": 7.5,
        "face_count": 30000  # æ§åˆ¶é¢æ•°ï¼Œå½±å“çº¹ç†è´¨é‡
    }
    
    try:
        print("ğŸ¨ å¼€å§‹ç”Ÿæˆå¸¦çº¹ç†çš„3Dæœºå™¨äººæ¨¡å‹...")
        print("â³ æ³¨æ„ï¼šçº¹ç†ç”Ÿæˆéœ€è¦æ›´é•¿æ—¶é—´ï¼ˆçº¦1-2åˆ†é’Ÿï¼‰...")
        
        response = runtime.invoke_endpoint(
            EndpointName=endpoint_name,
            ContentType='application/json',
            Body=json.dumps(test_payload)
        )
        
        result = json.loads(response['Body'].read().decode())
        
        if result.get('status') == 'completed' and 'model_base64' in result:
            # è§£ç å¹¶ä¿å­˜æ¨¡å‹æ–‡ä»¶
            model_data = base64.b64decode(result['model_base64'])
            
            output_file = 'textured_robot.glb'
            with open(output_file, 'wb') as f:
                f.write(model_data)
            
            print(f"âœ… å¸¦çº¹ç†çš„3Dæœºå™¨äººå·²ä¿å­˜åˆ°: {output_file}")
            print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {len(model_data)} å­—èŠ‚")
            print(f"ğŸ¨ ç°åœ¨åº”è¯¥èƒ½çœ‹åˆ°å½©è‰²çš„3Dæ¨¡å‹äº†ï¼")
            
        else:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {result}")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    generate_textured_model()